<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>blog - page 2 | Marvellous Oluwamayowa Ajala</title>
    <meta name="author" content="Marvellous Oluwamayowa Ajala" />
    <meta name="description" content="A pharmacist, ML engineer/researcher and research scientist in the making
" />
    <meta name="keywords" content="machine learning, drug discovery, healthcare, pharmacy" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.4.0/css/all.min.css" integrity="sha256-HtsXJanqjKTc8vVQjO4YMhiqFoXkfBsjBWcX91T1jr8=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light" />

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://ajalamarvellous.github.io/blog/page/2/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Marvellous&nbsp;</span>Oluwamayowa&nbsp;Ajala</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/projects/">projects</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/repositories/">repositories</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/teaching/">teaching</a>
              </li>
              <li class="nav-item dropdown ">
                <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus</a>
                <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown">
                  <a class="dropdown-item" href="/publications/">publications</a>
                  <div class="dropdown-divider"></div>
                  <a class="dropdown-item" href="/projects/">projects</a>
                </div>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <div class="post">

  
  

  
  <div class="header-bar">
    <h1>Blog</h1>
    <h2>a simple whitespace theme for academics</h2>
  </div>
  

  
  <div class="tag-category-list">
    <ul class="p-0 m-0">
      
        <li>
          <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/formatting">formatting</a>
        </li>
        
          <p>&bull;</p>
        
      
        <li>
          <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/images">images</a>
        </li>
        
          <p>&bull;</p>
        
      
        <li>
          <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/links">links</a>
        </li>
        
          <p>&bull;</p>
        
      
        <li>
          <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/math">math</a>
        </li>
        
          <p>&bull;</p>
        
      
        <li>
          <i class="fas fa-hashtag fa-sm"></i> <a href="/blog/tag/code">code</a>
        </li>
        
      
      
        <p>&bull;</p>
      
      
        <li>
          <i class="fas fa-tag fa-sm"></i> <a href="/blog/category/blockquotes">blockquotes</a>
        </li>
        
      
    </ul>
  </div>
  

  <ul class="post-list">
    

    
    
    
    

    <li><h3>
        
          <a class="post-title" href="/blog/2023/tables/">displaying beautiful tables with Bootstrap Tables</a>
        
      </h3>
      <p>an example of how to use Bootstrap Tables</p>
      <p class="post-meta">
        3 min read &nbsp; &middot; &nbsp;
        March 20, 2023
      </p>
      <p class="post-tags">
        <a href="/blog/2023">
          <i class="fas fa-calendar fa-sm"></i> 2023 </a>

          

          
          &nbsp; &middot; &nbsp;
            
            <a href="/blog/category/sample-posts">
              <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp;
              
          
    </p></li>

    

    
    
    
    

    <li><h3>
        
          <a class="post-title" href="/blog/2023/table-of-contents/">a post with table of contents</a>
        
      </h3>
      <p>an example of a blog post with table of contents</p>
      <p class="post-meta">
        3 min read &nbsp; &middot; &nbsp;
        March 20, 2023
      </p>
      <p class="post-tags">
        <a href="/blog/2023">
          <i class="fas fa-calendar fa-sm"></i> 2023 </a>

          

          
          &nbsp; &middot; &nbsp;
            
            <a href="/blog/category/sample-posts">
              <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp;
              
            <a href="/blog/category/toc">
              <i class="fas fa-tag fa-sm"></i> toc</a> &nbsp;
              
          
    </p></li>

    

    
    
    
    

    <li><h3>
        
          <a class="post-title" href="https://madeofajala.medium.com/the-beauty-and-the-beast-retrospection-of-conundrum-called-2022-abe9fd30c2ac?source=rss-4172ca26465e------2" target="_blank">The Beauty and The Beast: Retrospection of Conundrum called 2022</a>
          <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg">
            <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path>
          </svg>
        
      </h3>
      <p></p>
      <p class="post-meta">
        7 min read &nbsp; &middot; &nbsp;
        January 1, 2023
        &nbsp; &middot; &nbsp; medium.com
      </p>
      <p class="post-tags">
        <a href="/blog/2023">
          <i class="fas fa-calendar fa-sm"></i> 2023 </a>

          

          
    </p></li>

    

    
    
    
    

    <li><h3>
        
          <a class="post-title" href="/blog/2022/giscus-comments/">a post with giscus comments</a>
        
      </h3>
      <p>an example of a blog post with giscus comments</p>
      <p class="post-meta">
        1 min read &nbsp; &middot; &nbsp;
        December 10, 2022
      </p>
      <p class="post-tags">
        <a href="/blog/2022">
          <i class="fas fa-calendar fa-sm"></i> 2022 </a>

          

          
          &nbsp; &middot; &nbsp;
            
            <a href="/blog/category/sample-posts">
              <i class="fas fa-tag fa-sm"></i> sample-posts</a> &nbsp;
              
            <a href="/blog/category/external-services">
              <i class="fas fa-tag fa-sm"></i> external-services</a> &nbsp;
              
          
    </p></li>

    

    
    
    
    

    <li><h3>
        
          <a class="post-title" href="https://madeofajala.hashnode.dev/analysis-of-personal-feedback-i-got-from-my-friends-before-my-birthday" target="_blank">Analysis of personal feedback I got from my friends before my birthday</a>
          <svg width="2rem" height="2rem" viewBox="0 0 40 40" xmlns="http://www.w3.org/2000/svg">
            <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path>
          </svg>
        
      </h3>
      <p><h2 id="heading-introduction">Introduction</h2>
<p>So I put out a form a week before my birthday (July 18) asking for feedback from my friends and close pals (personal feedback) and I decided to convert the response I got into this mini project. 
In this article, I will be showing you how I did it and how you can also recreate it completely with python.</p>
<h3 id="heading-problem-statement">Problem statement</h3>
<p>I wanted to know what people's perception of me, get their criticisms (most recurring ones mean there is a problem to fix), what they think Im doing well enough and also general advice.</p>
<h3 id="heading-solution">Solution</h3>
<p>Exploratory data analysis of the response from the feedback form. After the analysis, the summary of the insight derived looked something like this:</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659136237724/-AcrR9b4G.jpg" alt="Birthday Feedback Analysis.jpg" /></p>
<h2 id="heading-tools">Tools</h2>
<ul>
<li>Pandas</li>
<li>Numpy</li>
<li>Matplotlib</li>
<li>Seaborn</li>
<li>sklearn</li>
<li>Wordcloud</li>
</ul>
<h2 id="heading-survey">Survey</h2>
<p>The form used was a simple google form that can be easily created using forms.google.com. The survey had four questions to determine: </p>
<ul>
<li>Peoples perception</li>
<li>Peoples criticisms</li>
<li>Positive feedback</li>
<li>General advice</li>
</ul>
<p>The form looked something like this</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054062056/zlHxw64Zi.png" alt="Screenshot 2022-07-29 at 01-20-28 jl Marvellous evaluation form.png" /></p>
<h2 id="heading-process">Process</h2>
<h3 id="heading-loading-the-data">Loading the data</h3>
<p>We will load the dataset using pandas, but first, let us import some of the libraries we will be using</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
</code></pre>
<p>We will be using pandas to analyse and extract our dataset. Pandas offer very nice tools to analyze data in one and two-dimensional formats known as data series and dataframes. They provide very nice extractions to get the information we need without having to rebuild the wheel every time.
Our dataset is a Comma separated value (CSV) data format in which each row represent a unique entry data and each unique value (each of the four questions we asked in the form) is separated by a comma. 
We will create a python object as dataframe (in-built pandas data structure) named df from our dataset My-feedback.csv</p>
<pre><code class="lang-python">df = pd.read_csv(<span class="hljs-string">"My-feedback.csv"</span>)
</code></pre>
<p>With pd.read_csv, we can easily read CSV data files.</p>
<h3 id="heading-basic-description">Basic description</h3>
<p>Next thing, we want to get basic descriptions of our dataset, lets view the first 5 rows</p>
<pre><code class="lang-python">df.head()
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054169436/F_vkp6l8z.png" alt="Screenshot 2022-07-29 at 01-22-03 JupyterLab.png" /></p>
<p>Next, lets get the shape (rows, columns) in our dataset, the number of rows of each column and their data types</p>
<pre><code class="lang-python">df.shape
</code></pre>
<p>(106,5)</p>
<pre><code class="lang-python">df.info()
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054341907/jSIrsK9w-.png" alt="image.png" /></p>
<p>Then, we also want a brief summary of the counts, unique values, most frequent values and their frequency</p>
<pre><code class="lang-python">df.describe()
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054382739/SNG32jyhH.png" alt="image.png" /></p>
<p>After that, let us get the names of the columns</p>
<pre><code class="lang-python">df.columns
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054410789/lCBpz1JUl.png" alt="image.png" /></p>
<h3 id="heading-preprocessing">Preprocessing</h3>
<p>Now, lets carry out some basic preprocessing on our data. We want to rename the columns from the very long names they have to much smaller and concise ones. To do that, we will create a dictionary match containing the present column names and the new names we want.</p>
<pre><code class="lang-python">new_columns = dict([(<span class="hljs-string">"What's your idea of who Marve is?"</span>, <span class="hljs-string">"Perception"</span>),
                    (<span class="hljs-string">"What's something I do you find particularly annoying, irritating or disgusting? Don't worry, it's completely anonymous. Or maybe something you just think I should stop"</span>, <span class="hljs-string">"Negative"</span>),
                    (<span class="hljs-string">"What do you think I do very well and I should double down on?"</span>, <span class="hljs-string">"Positive"</span>),
                    (<span class="hljs-string">"Any other advice you'll like to give me, or something you've been wanting to say to me?"</span>, <span class="hljs-string">"Suggestions"</span>)])
new_columns
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054450359/EkmS0MNLe.png" alt="image.png" /></p>
<p>Then we will rename the columns</p>
<pre><code class="lang-python">df = df.rename(columns=new_columns)
</code></pre>
<p>The next thing we want to do is to create two new columns containing the day (day name, whether Sunday, Monday or so) and hour people filled the form. First, we will convert the Timestamp column to a datetime datatype (under the df.info, it showed that it is an object type for all datatypes apart from integers, floats or decimals and booleans i.e True or false, but for us to extract insight from the timestamp column, we need to inform python/pandas that it is actually a date time value and not just strings)</p>
<pre><code class="lang-python">df[<span class="hljs-string">"Timestamp"</span>] = pd.to_datetime(df[<span class="hljs-string">"Timestamp"</span>])
</code></pre>
<p>Then we will extract the time and day</p>
<pre><code class="lang-python">df[<span class="hljs-string">"Day"</span>] = df[<span class="hljs-string">'Timestamp'</span>].dt.day_name()
df[<span class="hljs-string">"Hour"</span>] = df[<span class="hljs-string">'Timestamp'</span>].dt.hour
df.head()
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054533824/RaodKrf0Z.png" alt="image.png" /></p>
<p>After that, we want to bucket the time category, instead of having the hours, we want to convert them to categories such as morning (6:00am- 12:00pm), afternoon(12:00pm - 16:00pm), evening (16:00pm-20:00pm), night (20:00pm-00:00am) and midnight (00:00am - 06:00am)</p>
<pre><code class="lang-python">time_duration = [<span class="hljs-number">-1</span>,<span class="hljs-number">6</span>,<span class="hljs-number">12</span>,<span class="hljs-number">16</span>,<span class="hljs-number">20</span>, <span class="hljs-number">23</span>]
time_of_day = [<span class="hljs-string">"midnight"</span>, <span class="hljs-string">"morning"</span>, <span class="hljs-string">"afternoon"</span>, <span class="hljs-string">"evening"</span>, <span class="hljs-string">"night"</span>]
df[<span class="hljs-string">"Hour"</span>] = pd.cut(df[<span class="hljs-string">"Hour"</span>], time_duration, labels=time_of_day)
</code></pre>
<p>Then we will drop the Timestamp column, rename the Hour column to Time and reindex so that the Day and Time columns appear as the first and second columns instead of being the last two</p>
<pre><code class="lang-python">df = df.drop(<span class="hljs-string">"Timestamp"</span>, axis=<span class="hljs-number">1</span>)
df.rename(columns={<span class="hljs-string">"Hour"</span>:<span class="hljs-string">"Time"</span>}, inplace=<span class="hljs-literal">True</span>)
df =df.reindex(columns=[<span class="hljs-string">"Day"</span>, <span class="hljs-string">"Time"</span>, <span class="hljs-string">"Perception"</span>, <span class="hljs-string">"Negative"</span>, <span class="hljs-string">"Positive"</span>, <span class="hljs-string">"Suggestions"</span>])
df.head()
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054622721/b4nrWm1pP.png" alt="image.png" /></p>
<h3 id="heading-time-analysis">Time analysis</h3>
<p>So the first thing we want to know is which day people filled the form the most and what time of the day. To do that, we will create a function that we will be using to create our plots, this will prevent us from writing the same piece of code over and over again.</p>
<blockquote>
<p>This function <strong>plot_figure</strong> creates two types of plot, a barplot and a countplot, for countplot, we pass in a column and it basically counts the frequency and plot the frequency against the name while for barplots, we have to pass in both the Y values and X values. The function is set to create countplots by default and if we want a bar plot, we have to specify it under the plottype bar</p>
</blockquote>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_figure</span>(<span class="hljs-params">xvalues, yvalues=None, plottype=None, xlabel=None, ylabel=None, title=None, file_name=<span class="hljs-string">"sample.png"</span></span>):</span>
    fig, ax = plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">7</span>))
    ax.set_title(title)
    ax.set_xlabel(xlabel)
    ax.set_ylabel(ylabel)
    <span class="hljs-keyword">if</span> plottype == <span class="hljs-string">"bar"</span>:
        sns.barplot(x=xvalues, y=yvalues)
    <span class="hljs-keyword">else</span>:
        sns.countplot(x=xvalues)
    plt.savefig(file_name, dpi=<span class="hljs-number">500</span>, bbox_inches=<span class="hljs-string">"tight"</span>)
</code></pre>
<p>This function first of all creates a matplotlib figure upon which our chart will be placed, we want just one, figure, so we specified 1,1 for plt.subplots, meaning 1 on the X axis and 1 on the Y axis (altogether meaning 1), then we set the title, the X label and Y label), next we check if the plot type was specified as bar, if yes, plot a barplot, if not, plot a count plot. Then we save our image, the dpi (dots per inch) specifies the resolution we want for the image and bbox_inches to fit our chart and their labels in the image properly.</p>
<p>So now, we will create a chart to see the day people filled the form the most.</p>
<pre><code class="lang-python">plot_figure(df[<span class="hljs-string">"Day"</span>], xlabel=<span class="hljs-string">"Day"</span>, ylabel=<span class="hljs-string">"Count"</span>,
               title=<span class="hljs-string">"Day people filled the form the most"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054663134/PSut9PPAT.png" alt="image.png" /></p>
<p>Another thing we want is instead of plotting them just like that, we want to see from the day people filled the least to the day people filled the most. So we will get the count of the values in df[Day], express each value as a fraction of the total number we have in our data and sort the results</p>
<pre><code class="lang-python">data = df[<span class="hljs-string">"Day"</span>].value_counts(ascending=<span class="hljs-literal">True</span>, normalize=<span class="hljs-literal">True</span>)
data
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054900624/rPYh8uDDo.png" alt="image.png" /></p>
<p>Then we will plot this</p>
<pre><code class="lang-python">plot_figure(data.index, data.values, plottype=<span class="hljs-string">"bar"</span>, xlabel=<span class="hljs-string">"Days"</span>, ylabel=<span class="hljs-string">"Count"</span>,
               title=<span class="hljs-string">"Day people filled the form the most"</span>, file_name=<span class="hljs-string">"Day.png"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054874145/gukaWjwYF.png" alt="image.png" /></p>
<p>We can get the time people filled the most too</p>
<pre><code class="lang-python">plot_figure(df[<span class="hljs-string">"Time"</span>], xlabel=<span class="hljs-string">"Time"</span>, ylabel=<span class="hljs-string">"Count"</span>,
               title=<span class="hljs-string">"Time people filled the form the most"</span>, file_name=<span class="hljs-string">"Time.png"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659054979033/B0OWR1rZA.png" alt="image.png" /></p>
<p>The last thing we want to check under our analysis of the time is the time-day pair, which time of which day did people fill this form the most? 
To do this, we will group our data by day and time and find the size (the count)</p>
<pre><code class="lang-python">day_time = df.groupby([<span class="hljs-string">"Day"</span>, <span class="hljs-string">"Time"</span>]).size()
day_time[:<span class="hljs-number">10</span>]
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055014224/dDqf-kB60.png" alt="image.png" /></p>
<p>Next, we will  reassign the index to bear both the name and the time, the two values we used to group and sort the values, the new result looks like this</p>
<pre><code class="lang-python">day_time.index = day_time.index.values
day_time = day_time.sort_values()
day_time[:<span class="hljs-number">10</span>]
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055062303/63HLb0Emp.png" alt="image.png" /></p>
<p>So lets plot this to see only the top 10 values</p>
<pre><code class="lang-python">plot_figure(day_time.values[<span class="hljs-number">-10</span>:], day_time.index[<span class="hljs-number">-10</span>:], plottype=<span class="hljs-string">"bar"</span>, xlabel=<span class="hljs-string">"Count"</span>, ylabel=<span class="hljs-string">"Day and Time combination"</span>,
               title=<span class="hljs-string">"Day and time people filled the form the most"</span>, file_name=<span class="hljs-string">"Day_time.png"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055105624/esii1AOF8.png" alt="image.png" /></p>
<h3 id="heading-perception-analysis">Perception Analysis</h3>
<p>The next thing we want to do is to analyze the perception column, so lets assign it to a variable named perception, check the size and view the first 10 rows</p>
<pre><code class="lang-python">perceptions = df[<span class="hljs-string">"Perception"</span>]
print(perceptions.size)
perceptions.values[:<span class="hljs-number">10</span>]
</code></pre>
<p>106</p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055150796/G85k5vO9u.png" alt="image.png" /></p>
<p>So we will do some basic data cleaning, we want to remove all the punctuation in the data, and replace them with empty space (because some people dont add space before and after their punctuation, so the words dont end up being merged together), remove the preceding and trailing empty space for each sentence and convert all to lowercase (python will really interpret Python, python and PYTHON as all distinct values), so we will create functions to do this, to improve reusability of the codes.</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> sys
<span class="hljs-keyword">import</span> unicodedata

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_puncts</span>():</span>
    <span class="hljs-string">"""Create punctuations from punctuations in Unicode category"""</span>
    punctuation = dict([(i, <span class="hljs-string">" "</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(sys.maxunicode) <span class="hljs-keyword">if</span> unicodedata.category(chr(i)).startswith(<span class="hljs-string">'P'</span>)])
    <span class="hljs-keyword">return</span> punctuation


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">remove_punctuations</span>(<span class="hljs-params">x</span>):</span>
    <span class="hljs-string">"""Replace every punctuation in the sentence with an empty space"""</span>
    <span class="hljs-keyword">if</span> isinstance(x, str):
        <span class="hljs-keyword">return</span> x.translate(punctuations)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">clean_text</span>(<span class="hljs-params">x</span>):</span>
    <span class="hljs-string">"""clean the text to remove trailing and preceding spaces and convert all to small letters"""</span>
    <span class="hljs-comment"># remove unnecessary starting and ending space</span>
    x = x.strip()
    <span class="hljs-comment"># Convert them all to lowercase to avoid duplications</span>
    x = x.lower()
<span class="hljs-keyword">return</span> x
</code></pre>
<p>The first function checks for all the systems Unicode characters and created a dictionary for all characters that belong to the category of punctuation (not exactly the most optimal method out there but it works, hahaha) to be matched with an empty space. Next, we used the python string method, translate, to match and replace the punctuation in each sentence, and lastly, we cleaned each sentence to strip (remove unnecessary space) and covert to lower case. Now let us see our transformation on the dataset.</p>
<pre><code class="lang-python">punctuation =create_puncts()
perceptions = [string.translate(punctuations) <span class="hljs-keyword">for</span> string <span class="hljs-keyword">in</span> perceptions.values <span class="hljs-keyword">if</span> isinstance(string, str)]
perceptions = [clean_text(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> perceptions]
Perceptions[:<span class="hljs-number">10</span>]
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055186907/OGOiQTeCz.png" alt="image.png" /></p>
<p>Our data has basically been cleaned for us. So the next thing we will do is to convert all the functions we used to clean our data to just one function so we dont have to be calling them one after the other</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">parse_text</span>(<span class="hljs-params">dataframe, column</span>):</span>
    data = dataframe[column].values
    data = [sentence.translate(punctuations) <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> data <span class="hljs-keyword">if</span> isinstance(sentence, str)]
    data = [clean_text(sentence) <span class="hljs-keyword">for</span> sentence <span class="hljs-keyword">in</span> data]
<span class="hljs-keyword">return</span> data
</code></pre>
<p>Now that we have done this, we want to convert our data (the selected column) to a dataframe, where each column will be every word present in the entire column, we will also enable n_grams where we dont want just one word each but also pairs of words that occur together to better understand what they are trying to say. But we will stop here as we necessarily dont want to see the whole dataframe, we just wanted a way to see the most recurring words in every sentence. To do that, we will find the sum of every column and return only the number of top values we want to see, the words and their values (The more times a word or pair of words appear in the column, the higher the value of the sum will be since each appearance have a value of 1.</p>
<blockquote>
<p>Note that the dataframe we will create here will have the length of all the word-pairs in the dataset (or selected column of the original dataset) as its columns and the number of rows will be the same as in the original dataset minus the null values (the point in the previous function where we used dataframe[column].values removed the null values from our data). For each row, if a word or word pair exists in that row, the column bearing the word/word-pair has a value of 1, for other words and word pairs that are in the dataframe list of columns but don't appear in that row, they have a value of zero, thus making it easier for us to identify the words present in each row.</p>
</blockquote>
<pre><code class="lang-python"><span class="hljs-comment"># Import the package we will use</span>
<span class="hljs-keyword">from</span> sklearn.feature_extraction.text <span class="hljs-keyword">import</span> CountVectorizer

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_tops</span>(<span class="hljs-params">data, ntop, n_gram=<span class="hljs-number">2</span></span>):</span>
    vectorizer = CountVectorizer(ngram_range=(<span class="hljs-number">1</span>,n_gram), stop_words=<span class="hljs-string">"english"</span>)
    data = vectorizer.fit_transform(data)
    data = data.toarray()
    columns = vectorizer.get_feature_names_out()
    df = pd.DataFrame(data, columns=columns)
    most_freq = df.sum().sort_values(ascending=<span class="hljs-literal">False</span>)[:ntop]
<span class="hljs-keyword">return</span> most_freq
</code></pre>
<p>We used CountVectorizer to create our words dataframe, the ngram_range specifies how long the word pairs we want it to consider (if we set that to 2, then it will consider 2 words to make a pair e.g a sentence that contains This man is so rich apart from having each of the words as a column will also contain word pairs like This man, man is, so rich and many others as distinct columns too) and stop words to remove English stop words like is, I, his, to, of etc. Then we used fit transform to convert the list of rows to dataframe and convert it to an array (this is because it is saved as a sparse matrix to save memory)</p>
<blockquote>
<p>We use the sparse matrix in analysis for matrices (n,m) arrays that contain so many zeros and very few values</p>
</blockquote>
<p>After that, we used get_feature_names_out() to get the names of each column of the array, converted them to a dataframe, calculated the sum of each column (to see the most prevalent words in that data (column of the original dataset), sort the values in the descending order, largest to smallest and return the number of values I want to see. Lets get the values here.</p>
<pre><code class="lang-python">percep_data = parse_text(df, <span class="hljs-string">"Perception"</span>)
top50_percep = get_tops(percep_data, <span class="hljs-number">50</span>)
top50_percep[:<span class="hljs-number">10</span>]
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055246022/sQ-HBvyaD.png" alt="image.png" /></p>
<p>The next thing after this is very experimental, so we have to check the values to see the result. Sometimes, some of the words there may not make sense e.g guy, person, individual, person. While they are perfect English words, they do not carry the information we need, so we will have to check and remove them, sometimes, we may want to increase the number of words used to create our word pairs maybe we will be able to extract more meaning, anyhow you want to do it, you can tinker with it here. To drop any word or words, you can use</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">drop_values</span>(<span class="hljs-params">data, words</span>):</span>
<span class="hljs-keyword">return</span> data.drop(words)
</code></pre>
<p>So I will drop some words I dont think carry the information we are trying to get.</p>
<pre><code class="lang-python">values_2drop = [<span class="hljs-string">"guy"</span>, <span class="hljs-string">"person"</span>, <span class="hljs-string">"individual"</span>, <span class="hljs-string">"loves"</span>, <span class="hljs-string">"help"</span>, <span class="hljs-string">"man"</span>, <span class="hljs-string">"people"</span>, <span class="hljs-string">"don"</span>, <span class="hljs-string">"need"</span>, <span class="hljs-string">"talk"</span>, <span class="hljs-string">"says"</span>, <span class="hljs-string">"like"</span>, <span class="hljs-string">"things"</span>, <span class="hljs-string">"know"</span>]
top_percept = drop_values(top50_percep, values_2drop)
</code></pre>
<p>Next, we will plot a bar chart to visualize these top words</p>
<pre><code class="lang-python">plot_figure(top_percept.values, top_percept.index, plottype=<span class="hljs-string">"bar"</span>, xlabel=<span class="hljs-string">"Frequency"</span>,
            title=<span class="hljs-string">"People's top perception"</span>, file_name=<span class="hljs-string">"perception_bar.png"</span> )
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055275333/uAXuU4dJ0.png" alt="image.png" /></p>
<p>Another thing I wanted to create was a word cloud that will show the most frequent words in the data with their size depicting their frequency. To do that, we will be using word cloud, if you dont have it already on your PC, you can download it with pip using</p>
<pre><code class="lang-bash">pip install wordcloud
</code></pre>
<p>And there you go. To create the world cloud, we will import the word cloud package, create a distinct word cloud data that contains 200 words (this is because very few values will make our word cloud look scanty and unappealing), and convert them to a dictionary with the words being the keys and their frequency being the value, then we will create a function to plot, show and save the word cloud</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> wordcloud <span class="hljs-keyword">import</span> WordCloud

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">wordcloud_data</span>(<span class="hljs-params">data, values_2drop=None</span>):</span>
    cloud_data = get_tops(data, <span class="hljs-number">200</span>)
    <span class="hljs-keyword">if</span> values_2drop != <span class="hljs-literal">None</span>:
        cloud_data = drop_values(cloud_data, values_2drop)
    cloud_data = cloud_data.to_dict()
    <span class="hljs-keyword">return</span> cloud_data

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">create_wordcloud</span>(<span class="hljs-params">wordcloud, title=None, file_name=<span class="hljs-string">"sample.png"</span></span>):</span>
    fig, ax = plt.subplots(<span class="hljs-number">1</span>,<span class="hljs-number">1</span>, figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">8</span>))
    ax.set_title(title)
    cloud_plt = cloud.generate_from_frequencies(wordcloud)
    ax.imshow(cloud_plt)
    ax.axis(<span class="hljs-string">"off"</span>)
    plt.savefig(file_name, dpi=<span class="hljs-number">500</span>)
</code></pre>
<p>We will now create a word cloud for our Perception column of the original dataset.</p>
<pre><code class="lang-python">word_percept = wordcloud_data(percep_data)
create_wordcloud(word_percept, title= <span class="hljs-string">"World cloud of people's perception"</span>, file_name=<span class="hljs-string">"Wordcloud_percept.png"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055304893/777OdfGSi.png" alt="image.png" /></p>
<h2 id="heading-criticisms">Criticisms</h2>
<p>Since we have created all of the functions we will be using, we will just be calling this function. Lets get our criticism data and parse it</p>
<pre><code class="lang-python">critic_data = parse_text(df, <span class="hljs-string">"Negative"</span>)
top_critic = get_tops(critic_data, <span class="hljs-number">50</span>)
</code></pre>
<p>I had to tinker with this a lot also, tried n_gram=3 to see if I could extract more meaning, increased the ntops to view more values, I had to select just a few values that meaningfully contribute to the information I was trying to get.</p>
<pre><code class="lang-python">critics = [<span class="hljs-string">"insensitive jokes"</span>, <span class="hljs-string">"don know"</span>, <span class="hljs-string">"stop keeping nails"</span>, <span class="hljs-string">"haven seen"</span>, <span class="hljs-string">"banter"</span>, <span class="hljs-string">"nails"</span>, <span class="hljs-string">"eyes"</span>, 
          <span class="hljs-string">"focus"</span>, <span class="hljs-string">"jokes"</span>, <span class="hljs-string">"attention"</span>, <span class="hljs-string">"fashion sense"</span>, <span class="hljs-string">"grammar"</span>, <span class="hljs-string">"goodluck traveling"</span>, <span class="hljs-string">"eyes bag red"</span>,
          <span class="hljs-string">"forgetting food"</span>, <span class="hljs-string">"jokes ain funny"</span>, <span class="hljs-string">"kinda talk lot"</span>, <span class="hljs-string">"hear clearly"</span>, <span class="hljs-string">"haven seen bad"</span>, 
          <span class="hljs-string">"haven noticed"</span>, <span class="hljs-string">"haven observed"</span>]
critics = top_critic[critics].sort_values()
</code></pre>
<p>Then we will plot (barplot) the top values</p>
<pre><code class="lang-python">plot_figure(critics.values, critics.index, plottype=<span class="hljs-string">"bar"</span>, xlabel=<span class="hljs-string">"Frequency"</span>,
            title=<span class="hljs-string">"Criticism"</span>, file_name=<span class="hljs-string">"negative_bar.png"</span> )
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055446907/BRxCNVDd1.png" alt="image.png" /></p>
<p>Then we created the word cloud.</p>
<pre><code class="lang-python">critic_wordcloud = wordcloud_data(critic_data)
create_wordcloud(critic_wordcloud, title= <span class="hljs-string">"World cloud of people's Negative feedbacks"</span>, file_name=<span class="hljs-string">"Wordcloud_critic.png"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055487760/ZV4dMuI6w.png" alt="image.png" /></p>
<h3 id="heading-positive">Positive</h3>
<p>We will just recreate the same thing we did for criticisms for the positive feedback. Lets get and parse our data and also get the top positive feedback.</p>
<pre><code class="lang-python">pos_data = parse_text(df, <span class="hljs-string">"Positive"</span>)
top_pos = get_tops(pos_data, <span class="hljs-number">50</span>)
</code></pre>
<p>Next, we will plot the top 20 comments</p>
<pre><code class="lang-python">plot_figure(top_pos.values[:<span class="hljs-number">20</span>], top_pos[:<span class="hljs-number">20</span>].index, plottype=<span class="hljs-string">"bar"</span>, xlabel=<span class="hljs-string">"Frequency"</span>,
            title=<span class="hljs-string">"Positive feedback"</span>, file_name=<span class="hljs-string">"positive_bar.png"</span> )
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055512303/O1SPthMfK.png" alt="image.png" /></p>
<p>And the word cloud also</p>
<pre><code class="lang-python">word_pos = wordcloud_data(pos_data)
create_wordcloud(word_pos, title= <span class="hljs-string">"World cloud of people's perception"</span>, file_name=<span class="hljs-string">"Wordcloud_pos.png"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659055534307/Q1T-bzgd0.png" alt="image.png" /></p>
<h2 id="heading-sentiment-rating">Sentiment rating</h2>
<p>The last thing I want to do is to rate the sentiments on how positive (the positive feedback) or how negative (the criticisms) were. To do this, we will combine the positive feedback and criticism together while labelling the positive feedback as one and the negative feedback as zero (for our model to differentiate both), based on these values, we will train our machine learning model to give an estimated rating over 1 to each feedback. To do this:</p>
<pre><code class="lang-python">pos = parse_text(df, <span class="hljs-string">"Positive"</span>)
neg = parse_text(df, <span class="hljs-string">"Negative"</span>)
print(<span class="hljs-string">f"Length of positive comments: <span class="hljs-subst">{len(pos)}</span>"</span>)
print(<span class="hljs-string">f"Length of negative comments: <span class="hljs-subst">{len(neg)}</span>"</span>)
</code></pre>
<p>Length of positive comments: 101</p>
<p>Length of positive comments: 102</p>
<p>To extract and parse the positive feedback and criticism. Then we will combine both of them, with the first 101 rows being pos and the next 102 rows being neg</p>
<pre><code class="lang-python">combined = pos + neg
len(combined)
</code></pre>
<p>(203, )</p>
<p>Next, we will convert combined to a dataframe as we have always done.</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">make_df</span>(<span class="hljs-params">data</span>):</span>
    vectorizer = CountVectorizer(ngram_range=(<span class="hljs-number">1</span>,<span class="hljs-number">3</span>), stop_words=<span class="hljs-string">"english"</span>)
    data = vectorizer.fit_transform(data)
    data = data.toarray()
    columns = vectorizer.get_feature_names_out()
    df = pd.DataFrame(data, columns=columns)
<span class="hljs-keyword">return</span> df

comb_df = make_df(combined)
comb_df.shape
</code></pre>
<p>(203,1279)</p>
<p>Next, we will create the target values, and we will assign pos as 1 and neg as 0, remember, when we combined pos and neg to get our dataframe, the first 101 are pos and the remaining are neg. So we will use the same thing to create the target values too</p>
<pre><code># <span class="hljs-keyword">Create</span> target <span class="hljs-keyword">values</span>,  first <span class="hljs-number">101</span> = pos <span class="hljs-keyword">and</span> last <span class="hljs-number">102</span> = "neg"
target = np.concatenate([np.ones(<span class="hljs-number">101</span>), np.zeros(<span class="hljs-number">102</span>)])

target.shape
</code></pre><p>(203, )</p>
<p>Next, we will split our data into training and test set while also shuffling it, we dont want the training set to contain only pos or neg, we want both the training and test to combine both (train_test_split will also shuffle the data for us)</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(comb_df.values, target, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">2022</span>)
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = <span class="hljs-number">0.3</span>, random_state = <span class="hljs-number">2022</span>)

len(X_train), len(X_val), len(X_test), len(Y_train), len(Y_val), len(Y_test
</code></pre>
<p>(99, 43, 61, 99, 43, 61)</p>
<p>We split our data twice so as to have a test set and a validation set. For every model that we will try, we will evaluate them with the validation data and we will only use the test set to test the final selected model. This will make sure that we don't also overfit our data to the test set and that we have some data has never seen before to make a proper assessment of how our model performs in the presence of unseen data</p>
<p>We are going to scale the data next, try some models (Logistic Regression and Support Vector Machine) and find the best hyperparameters using GridSearch</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> GridSearchCV
<span class="hljs-keyword">from</span> sklearn.pipeline <span class="hljs-keyword">import</span> Pipeline
<span class="hljs-keyword">from</span> sklearn.preprocessing <span class="hljs-keyword">import</span> StandardScaler
<span class="hljs-keyword">from</span> sklearn.svm <span class="hljs-keyword">import</span> SVC
<span class="hljs-keyword">from</span> sklearn.linear_model <span class="hljs-keyword">import</span> LogisticRegression
</code></pre>
<p>Let us scale the data</p>
<pre><code class="lang-python">X_train_scaled = StandardScaler().fit_transform(X_train)
X_val_scaled = StandardScaler().fit_transform(X_val)
</code></pre>
<p>Let us train our logistic regression model using GridSearchCV.</p>
<blockquote>
<p>GridSearchCV combines Gridsearch to find the best hyperparameter i.e try all the hyperparameters we pass to find the one that will result in the best accuracy score and also perform cross-validation i.e splits our data into n folds, and combine different folds to train and different folds to test to avoid overfitting</p>
</blockquote>
<p>We will define the different parameters (C ) we want to use to train our logistic regression model, we will instantiate GridSearchCV and train the model</p>
<pre><code class="lang-python">param = dict([(<span class="hljs-string">"C"</span>, [<span class="hljs-number">0.001</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>])])
gridlogit = GridSearchCV(LogisticRegression(), param, cv=<span class="hljs-number">5</span>)
gridlogit.fit(X_train_scaled, Y_train)
</code></pre>
<p>We want to see how well our model did on both the training set and the validation set</p>
<pre><code class="lang-python">print(<span class="hljs-string">f" Best training accuracy: <span class="hljs-subst">{gridlogit.score(X_train_scaled, Y_train)}</span>"</span>)
print(<span class="hljs-string">f" Test accuracy: <span class="hljs-subst">{gridlogit.score(X_val_scaled, Y_val)}</span>"</span>)
</code></pre>
<p>Best training accuracy: 0.9595959595959596</p>
<p>Test accuracy: 0.6511627906976745</p>
<p>Our model has very obviously overfitted our data, we can see the drop-off from the training to the test dataset. Let us try a stronger model, let us try support vector machine.</p>
<pre><code class="lang-python">param = dict([
    (<span class="hljs-string">"C"</span>, [<span class="hljs-number">0.001</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>]),
    (<span class="hljs-string">"gamma"</span>, [<span class="hljs-number">0.001</span>, <span class="hljs-number">0.01</span>, <span class="hljs-number">0.1</span>, <span class="hljs-number">1</span>, <span class="hljs-number">10</span>, <span class="hljs-number">100</span>]),
              ])
gridcv = GridSearchCV(SVC(kernel=<span class="hljs-string">"rbf"</span>), param, cv=<span class="hljs-number">5</span>)
print(<span class="hljs-string">f" Best training accuracy: <span class="hljs-subst">{gridcv.fit(X_train_scaled, Y_train)}</span>"</span>)
print(<span class="hljs-string">f" Test accuracy: <span class="hljs-subst">{gridcv.score(X_test_scaled, Y_test)}</span>"</span>)
</code></pre>
<p>Best training accuracy: 0.971830985915493</p>
<p>Test accuracy: 0.5581395348837209</p>
<p>So it seems our Logistic Regression Model is the better one, after all, even though it is not really a great model, we will be using it like that. GridSearch automatically fits the best model to gridsearch, so we will be using it to evaluate our test data to get the actual performance of our model on unseen data</p>
<pre><code class="lang-python">X_test_scaled = StandardScaler().fit_transform(X_test) 
gridlogit.score(X_test_scaled, Y_test)
</code></pre>
<p>0.6557377049180327</p>
<p>The final thing we will be doing is to use our model to get the sentiment rating of our entire data, thus we will be getting the prediction probabilities of the entire data. To do this, we will get the original entire dataset, transform it and get the probability predictions (and not the predictions).</p>
<blockquote>
<p>We will be using the prediction probabilities because the predictions themselves will be 0 and 1 for criticisms and predictions respectively but instead we want the probability prediction from 0 to 1. The idea is as we move from very harsh criticisms to very positive feedback, the confidence of our model should go from 0 to 1, 0.1 being very harsh criticism (and very far from the positive feedback and vice versa) with mild compliments/criticisms ranging from 0.4 to 0.6 (meaning the positive feedback look like criticisms and the criticisms look like positive and thus the model cant easily separate them out).</p>
</blockquote>
<p>To do this, lets get the original combined dataset, transform it and get our probability predictions</p>
<pre><code class="lang-python">X = StandardScaler().fit_transform(comb_df.values)
rating = gridlogit.predict_proba(X)[:, <span class="hljs-number">1</span>]
</code></pre>
<p>This has generated predictions (over for each comment) whether it is a positive compliment or criticism and estimated the rating, but the values produced are floats (decimals) implying that they will all be unique. So we will bucket them such that all values from 0.0  0.1 will be in a group, and 0.1-0.2 will be in another group till we get to 1.</p>
<pre><code class="lang-python">new_Y = np.digitize(rating, bins=[<span class="hljs-number">0.1</span>,<span class="hljs-number">0.20</span>,<span class="hljs-number">0.30</span>,<span class="hljs-number">0.40</span>,<span class="hljs-number">0.50</span>,<span class="hljs-number">0.60</span>,<span class="hljs-number">0.70</span>,<span class="hljs-number">0.80</span>,<span class="hljs-number">0.90</span>,<span class="hljs-number">1</span>], right = <span class="hljs-literal">True</span>)
new_Y += <span class="hljs-number">1</span>
values, counts  = np.unique(new_Y, return_counts=<span class="hljs-literal">True</span>)
values = values/<span class="hljs-number">10</span>
counts = counts/np.sum(counts)
</code></pre>
<p>we add 1 to the values because numpy automatically assigns value 0 to the first group, and 1 to the second group, but we want to have values 1-10 representing the groups instead of 0-9, next, we then used np.unique method to get the values and their frequency of each of the values (using the return_counts parameter). Because our original prediction was over 1 (remember 1 represents the truest and best positive feedback we can get while 0 represents the worst criticisms), we divided by 10, to get this back. Then we converted the counts to be a fraction of the total number of values we have.
The final thing we want to do is to distinguish between positive feedback and criticism, so we want the plots for the positive feedback to face up on the Y-axis and that of criticism to face the other direction, so we would convert the values of criticisms (frequencies of 0.1- 0.5) to negative values, so seaborn can effect the change. To do that</p>
<pre><code class="lang-python">counts[:int(len(counts)/<span class="hljs-number">2</span>)] *= <span class="hljs-number">-1</span>
</code></pre>
<p>The last thing we will be doing is plotting this value now, we will add a little modification to the plot to add a pointer to the part of the graph that correlates with the positive feedback and criticisms.</p>
<pre><code class="lang-python">fig, ax = plt.subplots(<span class="hljs-number">1</span>, <span class="hljs-number">1</span>, figsize=(<span class="hljs-number">8</span>,<span class="hljs-number">7</span>))
sns.barplot(x=values,y=counts)
ax.yaxis.set_minor_locator(ticker.FixedLocator((<span class="hljs-number">-0.04</span>, <span class="hljs-number">0.05</span>)))
ax.yaxis.set_minor_formatter(ticker.FixedFormatter((<span class="hljs-string">'Criticisms'</span>, <span class="hljs-string">"Positive feedbacks"</span>)))
plt.setp(ax.yaxis.get_minorticklabels(), size=<span class="hljs-number">10</span>, va=<span class="hljs-string">"center"</span>)
ax.set_ylabel(<span class="hljs-string">"Frequency fraction"</span>)
ax.set_xlabel(<span class="hljs-string">"Sentiments"</span>)
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659131289582/Z-NF0LZ-v.png" alt="image.png" /></p>
<p>if we want the raw unfiltered plot, we can get that with</p>
<pre><code class="lang-python">plot_figure(new_Y, xlabel=<span class="hljs-string">"Sentiment Rating"</span>, ylabel = <span class="hljs-string">"Frequency"</span>,
            title=<span class="hljs-string">"Sentiment Ratings vs Frequency"</span>, file_name=<span class="hljs-string">"Sentiment_rating.png"</span> )
</code></pre>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1659131603214/-k8BRjmSS.png" alt="image.png" /></p>
<p>And that is the end of our project. If you enjoyed it or found it useful, please drop a reaction, comment and most importantly, share with someone else you think it might help, till the next one, selah.</p>
</p>
      <p class="post-meta">
        1 min read &nbsp; &middot; &nbsp;
        July 30, 2022
        &nbsp; &middot; &nbsp; hashnode.com
      </p>
      <p class="post-tags">
        <a href="/blog/2022">
          <i class="fas fa-calendar fa-sm"></i> 2022 </a>

          

          
    </p></li>

    
  </ul>

  <nav aria-label="Blog page naviation">
  <ul class="pagination pagination-lg justify-content-center">
    <li class="page-item ">
      <a class="page-link" href="/blog/" tabindex="-1" aria-disabled="1">Newer</a>
    </li><li class="page-item "><a class="page-link" href="/blog/index.html" title="blog">1</a></li>
      <li class="page-item active"><a class="page-link" href="/blog/page/2/index.html" title="blog - page 2">2</a></li>
      <li class="page-item "><a class="page-link" href="/blog/page/3/index.html" title="blog - page 3">3</a></li>
      <li class="page-item "><a class="page-link" href="/blog/page/4/index.html" title="blog - page 4">4</a></li>
      <li class="page-item "><a class="page-link" href="/blog/page/5/index.html" title="blog - page 5">5</a></li>
      <li class="page-item ">
      <a class="page-link" href="/blog/page/3/">Older</a>
    </li>
  </ul>
</nav>

</div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        &copy; Copyright 2023 Marvellous Oluwamayowa Ajala. Powered by <a href="https://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.4/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
